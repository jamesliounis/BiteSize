{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b2de3e-4df2-45b9-ba40-36bc14dbbbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade openai\n",
    "#pip install langchain\n",
    "#pip install pypdf \n",
    "#pip install faiss-cpu\n",
    "#pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "893d79ef-bdc9-49f1-9a2d-f916b1553cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "503cf741-d50a-4efa-b8f8-699a5d5b1cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file_obj = open('example2.pdf', 'rb')\n",
    "pdf_reader = PyPDF2.PdfReader(pdf_file_obj)\n",
    "num_pages = len(pdf_reader.pages)\n",
    "detected_text = ''\n",
    "\n",
    "for page_num in range(num_pages):\n",
    "    page_obj = pdf_reader.pages[page_num]\n",
    "    detected_text += page_obj.extract_text() + '\\n\\n'\n",
    "\n",
    "pdf_file_obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b14ba806-e8d1-4eac-be5f-6c4f62936ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain  is a framework for developing applications powered by language \\nmodels. You can use LangChain to build chatbots or personal assistants, to \\nsummarize, analyze, or generate Q&A over documents or structured data, to \\nwrite or understand code, to inter act with APIs, and to create other \\napplications that take advantage of  generative AI . There are currently two \\nversions of LangChain, one in  Python  and one in  TypeScript /JavaScript . \\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f196176-4a32-439e-9789-bbbf3d396598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['OPENAI_API_KEY'] = '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'\n",
    "#openai.api_key = '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'\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] =  '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'\n",
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad1ca498-deb0-4c6b-9807-42f712107011",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.create_documents([detected_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceb278fd-2ee8-4318-9e83-9f86bc5a954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"index_store\"\n",
    "vector_index = FAISS.from_documents(texts, OpenAIEmbeddings())\n",
    "vector_index.save_local(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "436302c9-fed8-4102-b958-d96be5a01ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = FAISS.load_local(\"index_store\", OpenAIEmbeddings())\n",
    "retriever = vector_index.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "qa_interface = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "167d76e6-fbc8-4a2d-9595-d45a45459b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_interface = ConversationalRetrievalChain.from_llm(ChatOpenAI(temperature=0), retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a18cdff-2189-487c-a8b2-145e5dd78c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_questions = 4\n",
    "total_marks = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f462f90-f763-4040-bad1-812cdf64d1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here are four questions about the document with their difficulty level, options, and answers:\n",
      "\n",
      "1. Question: What is LangChain used for?\n",
      "   Difficulty: Easy\n",
      "   Options:\n",
      "   a) Developing chatbots or personal assistants\n",
      "   b) Analyzing structured data\n",
      "   c) Writing or understanding code\n",
      "   d) All of the above\n",
      "   Answer: d) All of the above\n",
      "\n",
      "2. Question: How many versions of LangChain are currently available?\n",
      "   Difficulty: Easy\n",
      "   Options:\n",
      "   a) One\n",
      "   b) Two\n",
      "   c) Three\n",
      "   d) Four\n",
      "   Answer: b) Two\n",
      "\n",
      "3. Question: Which programming languages are supported by LangChain?\n",
      "   Difficulty: Medium\n",
      "   Options:\n",
      "   a) Python\n",
      "   b) TypeScript/JavaScript\n",
      "   c) Java\n",
      "   d) C++\n",
      "   Answer: a) Python and b) TypeScript/JavaScript\n",
      "\n",
      "4. Question: What can you do with LangChain?\n",
      "   Difficulty: Hard\n",
      "   Options:\n",
      "   a) Build chatbots or personal assistants\n",
      "   b) Summarize, analyze, or generate Q&A over documents or structured data\n",
      "   c) Interact with APIs\n",
      "   d) All of the above\n",
      "   Answer: d) All of the above\n",
      "\n",
      "Note: The difficulty levels are subjective and may vary based on individual perception.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "#query = \"ask me 5 questions of 100 total marks of varying difficulty and weightage based on the context\"\n",
    "query = 'ask '+str(num_questions)+' questions about the document exclusively, assign marks based on its difficulty (easy, medium, hard) so that it adds up to '+str(total_marks)+' marks. Give me the structure: number of question, questions, difficulty, options, answer'\n",
    "result = conv_interface({\"question\": query, \"chat_history\": chat_history})\n",
    "chat_history.append((query, result[\"answer\"]))\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "153b4432-21e1-42fb-9078-34e9a0cb5d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, option c is not the correct answer. The correct answer is that there are currently two versions of LangChain available: one in Python and one in TypeScript/JavaScript.\n"
     ]
    }
   ],
   "source": [
    "query = \"for the question 2: How many versions of LangChain are currently available? the answer is option c, is it correct? if it is not correct, give me the answer\"\n",
    "result = conv_interface({\"question\": query, \"chat_history\": chat_history})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2390d4d0-ee34-4f70-9b6d-222a34b6c0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-rZO3sTbBOavTuTNZCLmSVYRD on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-rZO3sTbBOavTuTNZCLmSVYRD on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-rZO3sTbBOavTuTNZCLmSVYRD on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-rZO3sTbBOavTuTNZCLmSVYRD on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-rZO3sTbBOavTuTNZCLmSVYRD on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-rZO3sTbBOavTuTNZCLmSVYRD on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-rZO3sTbBOavTuTNZCLmSVYRD on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-rZO3sTbBOavTuTNZCLmSVYRD on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given context, three options to choose from regarding the first question are:\n",
      "\n",
      "1. Building chatbots or personal assistants\n",
      "2. Summarizing, analyzing, or generating Q&A over documents or structured data\n",
      "3. Writing or understanding code\n"
     ]
    }
   ],
   "source": [
    "query = \"regarding the first question, give me 3 options to choose from\"\n",
    "result = conv_interface({\"question\": query, \"chat_history\": chat_history})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af872af9-7e65-4761-b210-9295acdbc808",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m parts \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m question \u001b[38;5;241m=\u001b[39m parts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m---> 14\u001b[0m difficulty_mark \u001b[38;5;241m=\u001b[39m \u001b[43mparts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m difficulty, mark \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+) - (\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+) marks\u001b[39m\u001b[38;5;124m'\u001b[39m, difficulty_mark)\u001b[38;5;241m.\u001b[39mgroups()\n\u001b[0;32m     16\u001b[0m questions\u001b[38;5;241m.\u001b[39mappend(question)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "lines = result[\"answer\"].split('\\n')\n",
    "\n",
    "# Initialize empty lists to store question, difficulty, and marks\n",
    "questions = []\n",
    "difficulties = []\n",
    "marks = []\n",
    "\n",
    "# Iterate through each line and extract information\n",
    "for line in lines:\n",
    "    # Check if the line contains a question\n",
    "    if line.strip().startswith(str(len(questions) + 1) + \".\"):\n",
    "        parts = line.split(\"(\")\n",
    "        question = parts[0].strip()\n",
    "        difficulty_mark = parts[1].strip().replace(\")\", \"\")\n",
    "        difficulty, mark = re.search(r'(\\w+) - (\\d+) marks', difficulty_mark).groups()\n",
    "        questions.append(question)\n",
    "        difficulties.append(difficulty.strip())\n",
    "        marks.append(int(mark.strip()))\n",
    "\n",
    "# Create a dataframe\n",
    "df = pd.DataFrame({'Question': questions, 'Difficulty': difficulties, 'Marks': marks})\n",
    "\n",
    "# Display the dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c67a03-8e05-4f22-b3bb-4de69a274f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.append((query, result[\"answer\"]))\n",
    "query = \"based on the previous options, the answer is 2., is it correct?, if not, give me the correct answer\"\n",
    "result = conv_interface({\"question\": query, \"chat_history\": chat_history})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250618db-abaf-4f33-b3ec-21d6c83ef437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TYPES OS QUESTIONS\n",
    "#1. OPEN ENDED\n",
    "#2. CLOSED ANSWER\n",
    "#3. CLOSED ANSWER WITH OPTIONS\n",
    "#4. T/F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cafcbef-c7ac-4943-80d8-b7ef63ea2979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THINGS TO DISCUSS / FEATURES\n",
    "#mark answer and give final score\n",
    "#will the questions be repeated?\n",
    "#open ai token to get more requests (now limited to 3/min)\n",
    "#tweak #of questions, type, marks, difficulty\n",
    "#use gpt3.5 or fine tune a model (?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
